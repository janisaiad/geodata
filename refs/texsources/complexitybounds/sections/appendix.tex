\onecolumn
\section*{Appendix}

\begin{proof} (Lemma~\ref{lem_pot_1})
For better clarity, we carry out the computations in dimension 1 but all the arguments are valid in higher dimension and we will clarify delicate points throughout the proof.

Differentiating both sides of the optimality condition \eqref{optim_condition} and rearranging yields
%$$
%-\frac{u'(x)}{\epsilon}\exp(\frac{-u(x)}{\epsilon}) = \int \frac{-c'(x,y)}{\epsilon} \exp(\frac{v(y)-c(x,y)}{\epsilon})\beta(y) dy.
%$$
%And thus the first order derivative of the potential can be expressed as
\begin{equation} \label{uprim}
u'(x) = \int c'(x,y) \gamma_\epsilon(x,y) \beta(y) dy.
\end{equation}

Notice that $\gamma_\epsilon'(x,y) = \frac{u'(x)-c'(x,y)}{\epsilon} \gamma_\epsilon(x,y)$. Thus by immediate recurrence (differentiating both sides of the equality again) we get that
\begin{equation}
u^{(n)}(x) =  \int g_n(x,y) \gamma_\epsilon(x,y) \beta(y) dy,
\end{equation}
where $g_{n+1} (x,y) = g_n' (x,y) + \frac{u'(x)-c'(x,y)}{\epsilon} g_n (x,y)$ and $g_1(x,y) = c'(x,y)$

To extend this first lemma to the $d$-dimensional case, we need to consider the sequence of indexes $\sigma = (\sigma_1,\sigma_2,\dots) \in \{1,\dots,d\}^{\NN}$ which corresponds to the axis along which we successively differentiate. Using the same reasoning as above, it is straightforward to check that
\eq{
\frac{\partial^k u}{\partial x_{\sigma_1}\dots\partial x_{\sigma_k}} = \int g_{\sigma,k} \gamma_{\epsilon}
}
where $g_{\sigma,1} = \frac{\partial c}{\partial x_{\sigma_1}}$ and $g_{\sigma,k+1} = \frac{\partial g_{\sigma,k+1}}{\partial x_{\sigma_{k+1}}} + \frac{1}{\epsilon} \left(  \frac{\partial u}{\partial x_{\sigma_{k+1}}} -  \frac{\partial c}{\partial x_{\sigma_{k+1}}} \right) g_{\sigma,k+1}$

\end{proof}

\begin{proof}(Lemma~\ref{lem_pot_2})
The proof is made by recurrence on the following property : \\
\textit{$P_n$ : For all $j=0,\dots,k $, for all $k=0,\dots,n-2$, $\norminf{g_{n-k}^{(j)}}$ is bounded by a polynomial  in $\frac{1}{\epsilon}$ of order $n-k+j-1$.} \\
Let us initialize the recurrence with $n=2$ 
\begin{eqnarray}
g_2 &= &g_1' + \frac{u'-c'}{\epsilon} g_1 \\
\norminf{g_2} &\leq & \norminf{g_1'} + \frac{\norminf{u'}+\norminf{c'}}{\epsilon} \norminf{g_1} 
\end{eqnarray}
Recall that  $\norminf{u'} = \norminf{g_1} = \norminf{c'}$.   Let $C = \max_{k} \norminf{c^{(k)}}$, we get that $\norminf{g_2}		\leq  C + \frac{C+C}{\epsilon} C$ which is of the required form.

Now assume that $P_n$ is true for some $n\geq2$. This means we have bounds on $g_{n-k}^{(i)}$, for $k=0,\dots,n-2$ and $i=0,\dots,k$. To prove the property at rank $n+1$ we want bounds on $g_{n+1-k}^{(i)}$, for $k=0,\dots,n-1$ and $i=0,\dots,k$. 
The only new quantity that we need to bound are  $g_{n+1-k}^{(k)}, k=0,\dots,n-1$.
Let us start by bounding $g_2^{(n-1)}$ which corresponds to $k=n-1$ and we will do a backward recurrence on $k$. By applying Leibniz formula for the successive derivatives of a product of functions, we get
\begin{eqnarray}
g_2 &=& g_1'+ \frac{u'-c'}{\epsilon} g_1 \\
g_2^{(n-1)} &=& g_1^{(n)} + \sum_{p=0}^{n-1} \binom{n-1}{p} \frac{u^{(p+1)}-c^{(p+1)}}{\epsilon} g_1^{(n-1-p)} \label{Leibniz}\\
\norminf{g_2^{(n-1)}} &\leq & \norminf{g_1^{(n)} }+ \sum_{p=0}^{n-1} \binom{n-1}{p} \frac{\norminf{u^{(p+1)}}+\norminf{c^{(p+1)}}}{\epsilon} \norminf{g_1^{(n-1-p)}} \\
&\leq & C + \sum_{p=0}^{n-1} \binom{n-1}{p} \frac{\norminf{g_{p+1}} + C }{\epsilon} C
\end{eqnarray}
Thanks to $P_n$ we have that  $\norminf{g_{p}}\leq \sum_{i=0}^{p} a_{i,p}\frac{1}{\epsilon^i} , p=1,\dots,n$ so the highest order term in $\epsilon$ in the above inequality is $\frac{1}{\epsilon^n}$. Thus we get
$\norminf{g_2^{(n-1)}} \leq  \sum_{i=0}^{n+1} a_{i,2,n-1}\frac{1}{\epsilon^i}$ which is of the expected order 

Now assume $g_{n+1-j}^{(j)}$ are bounded with the appropriate polynomials for $j < k\leq n-1$. Let us bound $g_{n+1-k}^{(k)}$
\begin{eqnarray}
\norminf{g_{n+1-k}^{(k)}} &\leq & \norminf{g_{n-k}^{(k+1)} }+ \sum_{p=0}^{k} \binom{k}{p} \frac{\norminf{u^{(p+1)}}+\norminf{c^{(p+1)}}}{\epsilon} \norminf{g_{n-k}^{(k-p)}} \\
								&\leq & \norminf{g_{n-k}^{(k+1)} }+ \sum_{p=0}^{k} \binom{k}{p} \frac{\norminf{g_{p+1}}+C}{\epsilon} \norminf{g_{n-k}^{(k-p)}}
\end{eqnarray}
The first term $\norminf{g_{n-k}^{(k+1)} }$  is bounded with a polynomial of order $\frac{1}{\epsilon^{n+1}}$ by recurrence assumption. Regarding the terms in the sum, they also have all been bounded and 
$$\norminf{g_{p+1}}\norminf{g_{n-k}^{(k-p)}} \leq \left( \sum_{i=0}^{p} a_{i,p+1}\frac{1}{\epsilon^i} \right) \left(\sum_{i=0}^{n-p} a_{i,n-k,k-p}\frac{1}{\epsilon^i} \right) \leq \sum_{i=0}^{n} \tilde a_i \frac{1}{\epsilon^i}$$

So $\norminf{g_{n+1-k}^{(k)}}  \leq \sum_{i=0}^{n+1} a_{i,n+1-k,k}\frac{1}{\epsilon^i} $

To extend the result in $\RR^d$, the recurrence is made on the the following property
\eql{
\norminf{g_{\sigma,n-k}^{(j)}} \leq \sum_{i=0}^{n-k+\abs{j}-1} a_{i,n-k,j,\sigma}\frac{1}{\epsilon^i} \qquad \forall j \mid \abs{j} = 0,\dots,k \quad \forall k=0,\dots,n-2 \quad \forall \sigma  \in \{ 1,\dots,d \}^{\NN}
}
where $j$ is a multi-index since we are dealing with multi-variate functions, and $g_{\sigma,n-k}$ is defined at the end of the previous proof. The computations can be carried out in the same way as above, using the multivariate version of Leibniz formula in \eqref{Leibniz} since we are now dealing with multi-indexes.
\end{proof}

