% !TEX root = ../SinkhornDivergenceUnbalanced.tex

\subsection{Properties of the Sinkhorn entropy}
\label{subsec-sink-entropy}

We first focus on the Sinkhorn entropy. 
% 
A key result is Proposition~\ref{thm-Feps_uniqueness} stating that $\Fb$ is convex.
It means that $\al\mapsto\OTb(\al,\al)$ is concave, which contrasts with the convexity of $\al\mapsto\OTb(\al,\be)$.
% which shows that $\OTb(\al,\be)$ is concave on the diagonal $\al=\be$ (in sharp contrast with its convexity as a function of $\al$ or $\be$ alone). 
%
%Before focusing on the equality of $\Fb(\al)$ and $\OTb(\al,\al)$, we prove that $\Fb$ is convex and admits a global minimizer. We emphasize that the properties of this section hold for any entropy $\phi$. They rely on a change of variable that we present now.
Theorem~\ref{thm-Feps_uniqueness} states the regularity of $\Fb$, but we need to reformulate it with the next result to ease its study.

\begin{proposition}[Change of variables in the symmetric $\OTb$ problem]\label{prop-entropy-reform}
Assuming that $\C$ is symmetric and such that the kernel $k_\epsilon=e^{-\C / \epsilon}$ is positive, one has
\begin{align*}
  \Fb(\al) = \inf_{\mu\in\Mmp(\Xx)}  \dotp{\al}{\phi^*\big(- \epsilon \log\big( \frac{\d\mu}{\d\al}\big)\,\big)} + \tfrac{\epsilon}{2} \Vert \mu \Vert^2_{k_\epsilon}.
\end{align*}
\end{proposition}
\begin{proof}
Similar to~\cite{feydy2018interpolating} for balanced OT, we perform a change of variable $\mu = e^{\f / \epsilon} \al$ to get
\begin{align*}
  \Fb(\al) 
  &= - \sup_{\f\in \Cc(\Xx)} -  \dotp{\al}{\phi^*(-\f)} -\tfrac{\epsilon}{2} \dotp{\al\otimes\al}{e^{\frac{\f\oplus \f - \C }{\epsilon}}}\\
  &= \inf_{\mu\sim\al}  \dotp{\al}{\phi^*\big(- \epsilon \log\big( \frac{\d\mu}{\d\al}\big)\,\big)} + \tfrac{\epsilon}{2} \Vert \mu \Vert^2_{k_\epsilon}\label{eq-constrained-entropy-program}
  = \inf_{\mu\in\Mmp(\Xx)}  \dotp{\al}{\phi^*\big(- \epsilon \log\big( \frac{\d\mu}{\d\al}\big)\,\big)} + \tfrac{\epsilon}{2} \Vert \mu \Vert^2_{k_\epsilon}.
\end{align*}
We relax the constraint $\mu\sim\al$ at the last line. 
The kernel $k_\epsilon$ is positive, so $\mu\ll\al$ can be removed.
Then $\al\ll\mu$ holds since $\lim_{q\rightarrow +\infty} \phi^*(q) = +\infty$. 
Otherwise, there is a $\al$-non-negligible set A s.t. $\frac{\d\mu}{\d\al}(x)=0$ $\alpha$-ae on $A$, so $\log \frac{\d\mu}{\d\al}=-\infty$.
\end{proof}


We can use Proposition~\ref{prop-entropy-reform} to prove the following theorem.

\begin{theorem}[Properties of the symmetric $\OTb$ problem]\label{thm-Feps_uniqueness}
Assume $\C$ is symmetric and $k_\epsilon=e^{-\C / \epsilon}$ is a positive universal kernel.
Then there exists a unique $\mu_\al\in\Mmp(\Xx)$ which attains the infimum, i.e. is such that
\begin{align*}
\Fb(\al)~=~  
\langle\al,\phi^*(-\epsilon\log \tfrac{\d\mu_\al}{\d\al})\rangle
+\tfrac{\epsilon}{2}
\langle \mu_\al, 
k_\epsilon\star \mu_\al \rangle.
\end{align*}
Moreover, $\al \sim \mu_\al$, and $\f = \epsilon\log\tfrac{\d\mu_\al}{\d\al}$ is the optimal dual potential for $\Fb(\al)$. Furthermore, $\Fb$ is strictly convex and is weak* continuous for all settings of Section~\ref{sec-exmp-f-div}. 
This implies that the Hausdorff divergence $\Hb$ is positive definite.
\end{theorem}

\begin{proof}
The proof is a generalization of~\cite{feydy2018interpolating} and is deferred in Appendix~\ref{appendix-proofs}.
\end{proof}

Proposition~\ref{prop-entropy-reform} involves a new variable $\mu_\al=e^{\f_\al / \epsilon}\al$.
The map $\al\mapsto\mu_\al$ appears to be injective, which matters for the definiteness of $\Sb$. 
%This property will be applied below, in Theorem~\ref{thm-Feps_uniqueness}.

\begin{lemma}[Injectivity of the symmetric $\OTb$ problem]\label{lem-injective-sym-pot}
	Note $\f_\al$ the optimal potential of $\Fb(\al)$. Assume $\C$ is symmetric.
	Then $\al\mapsto\al e^{\f_\al / \epsilon}$ is injective.
\end{lemma}
\begin{proof}
	Symmetry of $\C$ yields the optimality condition $\f=\Aa\Ss_\al(\f)$ on $\f$.
	Assume $\al e^{\f_\al / \epsilon} = \be e^{\g_\be / \epsilon}$ for some $(\al,\be)$. 
	This equality implies that $\dotp{\al}{e^{(\f_\al-\C(x,.)) / \epsilon}} = \dotp{\be}{e^{(\g_\be-\C(x,.)) / \epsilon}}$. After composing with the log and the aprox, we get	$-\aprox{\phi^*}(-\Ss_\al(\f_\al)) = -\aprox{\phi^*}(-\Ss_\be(\g_\be))$.
	By optimality of $(\f_\al,\g_\be)$ we have $\f_\al = \g_\be$, thus the relation $\al e^{\f_\al / \epsilon} = \be e^{\g_\be / \epsilon}$ implies $\al=\be$.
\end{proof}

%\begin{proposition}\label{prop-entropy-cvx-unb}
%Assuming the kernel $k_\epsilon=e^{-\C / \epsilon}$ to be positive universal, the Unbalanced Sinkhorn entropy $\Fb$ is convex. Furthermore, $\Fb$ is strictly convex, thus the Hausdorff divergence is positive definite.
%\end{proposition}
%\begin{proof}
%Using Proposition~\ref{prop-entropy-reform}, $\Fb$ is the minimization of a norm and a $\phi$-divergence which are both jointly convex in $(\al,\mu)$ provided the function $\psi=\phi\circ(-\epsilon \log)$ is convex, and the kernel is positive.
%\todo{Correct this proof with the remarks of AT}
%A general result from convex theory gives that the composition of two convex functions $f\circ g$ with $f$ nondecreasing is also convex. The function $\psi$ is convex because $-\log$ is convex and $\phi^*$ is a non-decreasing convex function on $\R$ (Proposition~\ref{prop-legendre-conj}).
%The functional $\Fb$ is the minimization of a jointly convex function on a convex set, hence its convexity.
%
%To prove that it is strictly convex, we need to prove that the functional is strictly convex and attains its optimum. The functional is the sum of a convex $\phi$-divergence and a strictly convex kernel norm. Theorem~\ref{thm-Feps_uniqueness} applies and gives that the minimum is attained in $\Mmpp(\Xx)$. From Lemma~\ref{lem-inf-strict-cvx} we deduce that $\Fb$ is also strictly convex.
%\end{proof}
%\begin{proof}
%	We use Equation~\eqref{eq-constrained-entropy-program} from Proposition~\ref{prop-entropy-reform}. It allows to add the constraint set $I = \{(\al,\mu)\in\Mmp(\Xx),\, \al\sim\mu\}$ which is jointly convex in $(\al,\mu)$. Write the energy as $E_\epsilon(\al,\mu) = \dotp{\al}{\phi^*\big(- \epsilon \log\big( \frac{\d\mu}{\d\al}\big)\,\big)} + \tfrac{\epsilon}{2} \Vert \mu \Vert^2_{k_\epsilon}$. The function $\psi = \phi^* \circ (-\epsilon\log)$ is convex because both functions are convex and $\phi^*$ is nondecreasing. On the set $I$, $\al$ verifies $\al^\bot=0$ w.r.t. $\mu$, thus the term $\dotp{\al}{\phi^*\big(- \epsilon \log\big( \frac{\d\mu}{\d\al}\big)\,\big)}$ can be identified as a $\psi$-divergence and is thus jointly convex in $(\al,\mu)$. The norm $\norm{.}_{k_\epsilon}$ is jointly convex. Eventually, we minimize a jointly convex function over a (jointly) convex set, and we get that $\Fb$ is convex.
%	
%	To prove the strict convexity, we use Proposition~\ref{lem-injective-sym-pot} which gives that for two measures $\al\neq\be$ one has $\mu_\al\neq\mu_\be$ where both measure are the one attaining the optimal in $\Fb(\al)$ and $\Fb(\be)$. Since $k_\epsilon$ is universal the norm $\norm{.}_{k_\epsilon}$ is strictly convex when $\mu_\al\neq\mu_\be$. Write $\bar{\mu}$ the optimal measure for $t\al + (1-t)\be$ with $t\in(0,1)$. One has
%	\begin{align*}
%		\Fb(t\al + (1-t)\be) &= E_\epsilon(t\al + (1-t)\be, \bar{\mu})\\
%		&\leq E_\epsilon(t\al + (1-t)\be, t\mu_\al + (1-t)\mu_\be)\\
%		&< t E_\epsilon(\al,\mu_\al) + (1-t) E_\epsilon(\be,\mu_\be)\\
%		&< t \Fb(\al) + (1-t) \Fb(\be).
%	\end{align*}
%	Hence the strict convexity of the Sinkhorn entropy.
%\end{proof}

We state the link between $\Fb$ and $\OTb$ when the problem is symmetric.
The properties of $\Sb$ rely heavily on it.
As discussed in~\cite{knight2014symmetry,feydy2020thesis} for balanced OT, the potential $\f_\al$ is much faster to compute in the symmetric setting, which matters to compute $\OTb(\al,\al)$.
%
%We state the equality between symmetric OT and the Sinkhorn entropy, which relies on the symmetry of the problem. 
%This result is strong because the existence of a symmetric potential that reaches the optimum of $\OTb(\al,\al)$ is not obvious in the absence of strict convexity.
%The properties of the Sinkhorn divergence rely heavily on this result.
%Note that as discussed in \cite{knight2014symmetry,feydy2020thesis} in the balanced setting, the regularized optimal transport problem can be solved (much) faster in the symmetric than in the general case.s

\begin{proposition}%[Link between $\Fb$ and $\OTb$]
	\label{lem-sym-pot}
If $\C$ is symmetric, Then $\Fb(\al)=-\tfrac{1}{2}\OTb(\al,\al) + \tfrac{\epsilon}{2}m(\al)^2$.
\end{proposition}
\begin{proof}
There exists an optimal potential $\f$ for $\Fb$ (Theorem~\ref{thm-Feps_uniqueness}). 
The pair $(\f,\f)$ is suboptimal for $\OTb(\al,\al)$, thus $\Fb(\al)\leq -\tfrac{1}{2}\OTb(\al,\al) + \tfrac{\epsilon}{2}m(\al)^2$.

We use a primal suboptimality argument to get the other inequality. 
Consider the plan $\pi = e^{(\f\oplus\f-\C) / \epsilon}\al\otimes\al$. 
The marginals read $\pi_1=\pi_2=\dotp{\al}{e^{(\f-\C) / \epsilon}}e^{\f / \epsilon}\al$ since $\C$ is symmetric. 
Thanks to symmetry, the optimality condition on $\Ff(\f,\f)$ reads ($ \frac{\d\pi_i}{\d\al} = \dotp{\al}{e^{(\f-\C) / \epsilon}}e^{\f / \epsilon} \in \partial\phi^*(-\f)$.
It is equivalent to $\phi^*(-\f(x)) + \phi(\frac{\d\pi_i}{\d\al}(x)) = -\f(x)\frac{\d\pi_i}{\d\al}(x)$ for any $x\in\Xx$.
%\begin{align*}
%    &\frac{\d\pi_i}{\d\al} = \dotp{\al}{e^{(\f-\C) / \epsilon}}e^{\f / \epsilon} \in \partial\phi^*(-\f)\\
%    &\Leftrightarrow \forall x\in\Xx,\; \phi^*(-\f(x)) + \phi(\frac{\d\pi_i}{\d\al}(x)) = -\f(x)\frac{\d\pi_i}{\d\al}(x).
%\end{align*}
The suboptimality of $\pi$ reads
\begin{align*}
    \OTb(\al,\al) \leq \dotp{\pi}{\C} + \rho\D_\phi(\pi_1|\al) + \rho\D_\phi(\pi_2|\al) + \epsilon\KL(\pi|\al\otimes\al),
\end{align*}
where
   $ \D_\phi(\pi_i|\al) = \dotp{\al}{\phi(\frac{\d\pi_i}{\d\al})}
    = \dotp{\al}{-\f\frac{\d\pi_i}{\d\al} - \phi^*(-\f)},$
and
\begin{align*}
    \epsilon\KL(\pi|\al\otimes\al) &= \epsilon\dotp{\pi}{\log\frac{\d\pi}{\d\al\d\al}} - \epsilon m(\pi) + \epsilon m(\al)^2\\
    &= \dotp{\pi}{\f\oplus\f-\C} - \epsilon\dotp{\al\otimes\al}{e^{\tfrac{\f\oplus\f-\C}{\epsilon}} - 1}\\
    &= \dotp{\pi_1}{\f} + \dotp{\pi_2}{\f} - \dotp{\pi}{\C}- \epsilon\dotp{\al\otimes\al}{e^{\tfrac{\f\oplus\f-\C}{\epsilon}} - 1}\\
    &= \dotp{\al}{\f\frac{\d\pi_1}{\d\al}} + \dotp{\al}{\f\frac{\d\pi_2}{\d\al}} - \dotp{\pi}{\C}- \epsilon\dotp{\al\otimes\al}{e^{\tfrac{\f\oplus\f-\C}{\epsilon}} - 1}.
\end{align*}
Summing everything, we get the inequality $\OTb(\al,\al)\leq -2\Fb(\al) + \epsilon m(\al)^2$, hence the desired equality.
\end{proof}
